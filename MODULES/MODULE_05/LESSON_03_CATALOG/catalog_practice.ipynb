{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a85acb-d4ac-42d6-8385-4067def2c3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------------------------------------------------------------------------------+\n",
      "|info_name     |info_value                                                                                  |\n",
      "+--------------+--------------------------------------------------------------------------------------------+\n",
      "|Catalog Name  |spark_catalog                                                                               |\n",
      "|Namespace Name|retail_db                                                                                   |\n",
      "|Comment       |                                                                                            |\n",
      "|Location      |file:/home/jovyan/workspace/MODULES/MODULE_05/LESSON_03_CATALOG/spark-warehouse/retail_db.db|\n",
      "|Owner         |jovyan                                                                                      |\n",
      "+--------------+--------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "\n",
    "# –í–∫–ª—é—á–∞–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É Hive (—Ö–æ—Ç—è –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –¥–æ–∫–µ—Ä–µ —ç—Ç–æ —á–∞—Å—Ç–æ —ç–º—É–ª—è—Ü–∏—è —á–µ—Ä–µ–∑ Derby)\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Catalog_Lab\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 1. –°–æ–∑–¥–∞–µ–º –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS retail_db\")\n",
    "\n",
    "# 2. –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –Ω–µ—ë\n",
    "spark.sql(\"USE retail_db\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º, –≥–¥–µ Spark —Å–æ–±–∏—Ä–∞–µ—Ç—Å—è —Ö—Ä–∞–Ω–∏—Ç—å —Ç–∞–±–ª–∏—Ü—ã —ç—Ç–æ–π –±–∞–∑—ã\n",
    "spark.sql(\"DESCRIBE DATABASE retail_db\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840925b-2ee9-4ebb-897d-0d785e8b455d",
   "metadata": {},
   "source": [
    "### Managed Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b47d849-f398-4bae-b12d-8114294b0b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------------------------------------------------------------------------------------------+-------+\n",
      "|col_name|data_type                                                                                                 |comment|\n",
      "+--------+----------------------------------------------------------------------------------------------------------+-------+\n",
      "|Location|file:/home/jovyan/workspace/MODULES/MODULE_05/LESSON_03_CATALOG/spark-warehouse/retail_db.db/managed_items|       |\n",
      "+--------+----------------------------------------------------------------------------------------------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "df = spark.createDataFrame([(1, \"Item A\"), (2, \"Item B\")], [\"id\", \"name\"])\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ MANAGED —Ç–∞–±–ª–∏—Ü—É (–ø—Ä–æ—Å—Ç–æ saveAsTable –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –ø—É—Ç–∏)\n",
    "df.write.mode(\"overwrite\").saveAsTable(\"managed_items\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º, –≥–¥–µ –æ–Ω–∞ –ª–µ–∂–∏—Ç\n",
    "spark.sql(\"DESCRIBE EXTENDED managed_items\").filter(\"col_name = 'Location'\").show(truncate=False)\n",
    "# –í—ã —É–≤–∏–¥–∏—Ç–µ –ø—É—Ç—å –≤–Ω—É—Ç—Ä–∏ –ø–∞–ø–∫–∏ spark-warehouse\n",
    "\n",
    "# –£–¥–∞–ª–µ–Ω–∏–µ (–í–ù–ò–ú–ê–ù–ò–ï: –£–¥–∞–ª–∏—Ç –∏ —Ñ–∞–π–ª—ã!)\n",
    "# spark.sql(\"DROP TABLE managed_items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a5183-be35-4055-97fd-118101fac01d",
   "metadata": {},
   "source": [
    "### External Table (–ë–µ–∑–æ–ø–∞—Å–Ω–æ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6559abe-a322-4e96-acad-0047fed49057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+-------+\n",
      "|col_name|data_type|comment|\n",
      "+--------+---------+-------+\n",
      "|    Type| EXTERNAL|       |\n",
      "+--------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. –°–Ω–∞—á–∞–ª–∞ –ø–∏—à–µ–º —Ñ–∞–π–ª—ã –≤ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ –º–µ—Å—Ç–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä, /tmp/data)\n",
    "external_path = \"/home/jovyan/workspace/data/external_items\"\n",
    "df.write.mode(\"overwrite\").parquet(external_path)\n",
    "\n",
    "# 2. –°–æ–∑–¥–∞–µ–º –í–ù–ï–®–ù–Æ–Æ —Ç–∞–±–ª–∏—Ü—É, —É–∫–∞–∑—ã–≤–∞—è LOCATION\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE TABLE external_items (\n",
    "        id INT,\n",
    "        name STRING\n",
    "    )\n",
    "    USING PARQUET\n",
    "    LOCATION '{external_path}'\n",
    "\"\"\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∏–º —Ç–∏–ø\n",
    "spark.sql(\"DESCRIBE EXTENDED external_items\").filter(\"col_name = 'Type'\").show()\n",
    "# –î–æ–ª–∂–Ω–æ –±—ã—Ç—å: EXTERNAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3054c5f6-d59a-4f11-8cb3-7a3a9b94a8fb",
   "metadata": {},
   "source": [
    "### Python API –∫–∞—Ç–∞–ª–æ–≥–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c90bb297-3a27-4353-8a99-72c1e9e9769c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table: external_items, Type: EXTERNAL\n",
      "Table: managed_items, Type: MANAGED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 45572)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 317, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 348, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 361, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/opt/conda/lib/python3.11/socketserver.py\", line 755, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "                           ^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/spark/python/pyspark/serializers.py\", line 596, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# –ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–∞–±–ª–∏—Ü –≤ –±–∞–∑–µ\n",
    "tables = spark.catalog.listTables(\"retail_db\")\n",
    "\n",
    "for t in tables:\n",
    "    print(f\"Table: {t.name}, Type: {t.tableType}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edfbb83-4d36-485b-9ad9-9b1034745808",
   "metadata": {},
   "source": [
    "### –ê–Ω—Ç–∏-–ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏ –û—à–∏–±–∫–∏\n",
    "\n",
    "üö´ –û—à–∏–±–∫–∞ 1: CTAS (Create Table As Select) –±–µ–∑ –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–∏–ø–∞\n",
    "- –ö–æ–¥: df.write.saveAsTable(\"my_backup\")\n",
    "- –ü—Ä–æ–±–ª–µ–º–∞: –≠—Ç–æ —Å–æ–∑–¥–∞–µ—Ç Managed —Ç–∞–±–ª–∏—Ü—É. –ï—Å–ª–∏ –≤—ã –∏–ª–∏ –∫–æ–ª–ª–µ–≥–∞ —Ä–µ—à–∏—Ç–µ \"–ø–æ—á–∏—Å—Ç–∏—Ç—å –±–∞–∑—É\" –∏ —Å–¥–µ–ª–∞–µ—Ç–µ DROP TABLE my_backup, –±—ç–∫–∞–ø –∏—Å—á–µ–∑–Ω–µ—Ç —Ñ–∏–∑–∏—á–µ—Å–∫–∏.\n",
    "- –†–µ—à–µ–Ω–∏–µ: –í—Å–µ–≥–¥–∞ —è–≤–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ .option(\"path\", \"/secure/location\") –ø—Ä–∏ saveAsTable, —á—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –µ—ë –≤–Ω–µ—à–Ω–µ–π (–≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö) –∏–ª–∏ —Å–æ–∑–¥–∞–≤–∞–π—Ç–µ —á–µ—Ä–µ–∑ SQL CREATE EXTERNAL TABLE.\n",
    "\n",
    "üö´ –û—à–∏–±–∫–∞ 2: –†–∞—Å—Å–∏–Ω—Ö—Ä–æ–Ω –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö  \n",
    "- –°—Ü–µ–Ω–∞—Ä–∏–π: –í—ã —É–¥–∞–ª–∏–ª–∏ —Ñ–∞–π–ª—ã —Ä—É–∫–∞–º–∏ —á–µ—Ä–µ–∑ —Ç–µ—Ä–º–∏–Ω–∞–ª (rm -rf ...), –Ω–æ –Ω–µ —É–¥–∞–ª–∏–ª–∏ —Ç–∞–±–ª–∏—Ü—É –≤ Spark.\n",
    "- –†–µ–∑—É–ª—å—Ç–∞—Ç: Spark –¥—É–º–∞–µ—Ç, —á—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ –µ—Å—Ç—å, –Ω–æ –ø—Ä–∏ SELECT –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π FileNotFoundException.\n",
    "- –†–µ—à–µ–Ω–∏–µ: –ö–æ–º–∞–Ω–¥–∞ MSCK REPAIR TABLE my_table (–¥–ª—è –ø–∞—Ä—Ç–∏—Ü–∏–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü) –∏–ª–∏ REFRESH TABLE my_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d48376-4f99-4cd5-a816-3e30cfaca5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
