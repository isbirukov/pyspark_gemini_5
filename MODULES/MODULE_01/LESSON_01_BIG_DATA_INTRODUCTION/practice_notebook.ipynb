{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb476b35-c62e-4f54-97c3-0b7bfaaa267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ SparkSession —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!\n",
      "–í–µ—Ä—Å–∏—è Spark: 3.5.0\n",
      "–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: IntroToBigData\n",
      "Master URL: local[*]\n"
     ]
    }
   ],
   "source": [
    "# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∫–ª–∞—Å—Å SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# 1. –°–æ–∑–¥–∞–Ω–∏–µ SparkSession\n",
    "# .builder - –Ω–∞—á–∏–Ω–∞–µ—Ç —Å–±–æ—Ä–∫—É —Å–µ—Å—Å–∏–∏\n",
    "# .appName(\"IntroToBigData\") - –∑–∞–¥–∞–µ—Ç –∏–º—è –Ω–∞—à–µ–º—É –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—é (–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤ Spark UI)\n",
    "# .getOrCreate() - –µ—Å–ª–∏ —Å–µ—Å—Å–∏—è —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ—ë; –∏–Ω–∞—á–µ - —Å–æ–∑–¥–∞–µ—Ç –Ω–æ–≤—É—é\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"IntroToBigData\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "# –í—ã–≤–µ–¥–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–∑–¥–∞–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏\n",
    "print(\"üéâ SparkSession —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞!\")\n",
    "print(f\"–í–µ—Ä—Å–∏—è Spark: {spark.version}\")\n",
    "print(f\"–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {spark.sparkContext.appName}\")\n",
    "\n",
    "# –í–∞–∂–Ω–æ–µ –ø–æ–Ω—è—Ç–∏–µ: SparkContext. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ä–µ–∂–µ, –Ω–æ —É–ø—Ä–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Ç–µ—Ä–æ–º\n",
    "sc = spark.sparkContext\n",
    "print(f\"Master URL: {sc.master}\") \n",
    "\n",
    "# 2. –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Å–µ—Å—Å–∏–∏ (–≤—Å–µ–≥–¥–∞ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –≤ –∫–æ–Ω—Ü–µ —Ä–∞–±–æ—Ç—ã, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã)\n",
    "# spark.stop() \n",
    "# *–î–ª—è Jupyter/Notebooks —á–∞—Å—Ç–æ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è, –Ω–æ —ç—Ç–æ Best Practice –¥–ª—è —Å–∫—Ä–∏–ø—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62a3e71-543c-432a-a366-cdc3c9347408",
   "metadata": {},
   "source": [
    "## Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a989529-2b64-4513-81bf-721d3c93e984",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞—á–∞ 1.1. (–ü—Ä–æ—Å—Ç–æ–µ –∏–º—è):\n",
    "- –°–æ–∑–¥–∞–π—Ç–µ SparkSession —Å –∏–º–µ–Ω–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è 'Simple_App_01' –∏ –≤—ã–≤–µ–¥–∏—Ç–µ –≤–µ—Ä—Å–∏—é Spark. –ó–∞—Ç–µ–º –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Å–µ—Å—Å–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc3f5ee2-6864-4f1f-9500-004aebb33d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í–µ—Ä—Å–∏—è Spark: 3.5.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Simple_App_01\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(f\"–í–µ—Ä—Å–∏—è Spark: {spark.version}\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffeb478-9c4a-4cac-8dd5-5542d3e077bb",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞—á–∞ 1.2. (–°–ª–æ–∂–Ω–æ–µ –∏–º—è): \n",
    "- –°–æ–∑–¥–∞–π—Ç–µ SparkSession —Å –∏–º–µ–Ω–µ–º, –∏–º–∏—Ç–∏—Ä—É—é—â–∏–º ETL-–ø–∞–π–ø–ª–∞–π–Ω: 'ETL_Daily_User_Log_Processor_V1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f851ea77-de10-4047-ad78-cb40296c01fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"ETL_Daily_User_Log_Processor_V1\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0871e9a-1177-4252-b8de-e0587a279f4a",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞—á–∞ 1.3. (–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ —Å–æ–∑–¥–∞–Ω–∏–µ):\n",
    "- –ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Å—Å–∏—é. –ó–∞—Ç–µ–º –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–æ–∑–¥–∞—Ç—å –Ω–æ–≤—É—é —Å–µ—Å—Å–∏—é —Å –¥—Ä—É–≥–∏–º –∏–º–µ–Ω–µ–º (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'Second_Attempt'). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –∫–∞–∫–æ–µ –∏–º—è –±—É–¥–µ—Ç —É –∞–∫—Ç–∏–≤–Ω–æ–π —Å–µ—Å—Å–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è .getOrCreate() (–æ—Ç–≤–µ—Ç: –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –ø–µ—Ä–≤–∞—è –∞–∫—Ç–∏–≤–Ω–∞—è —Å–µ—Å—Å–∏—è)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c9ec82-0e90-4210-8976-8013dc66f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: ETL_Daily_User_Log_Processor_V1\n"
     ]
    }
   ],
   "source": [
    "spark_new_session = SparkSession.builder \\\n",
    "        .appName(\"Second_Attempt\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "print(f\"–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {spark.sparkContext.appName}\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05418b4a-7d2d-4502-a013-50634163c7a5",
   "metadata": {},
   "source": [
    "### –ö–µ–π—Å 1.4. (–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤): \n",
    "–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ SparkSession –∏ –≤—ã–≤–µ–¥–∏—Ç–µ –Ω–∞ —ç–∫—Ä–∞–Ω URL –º–∞—Å—Ç–µ—Ä–∞ (sc.master) –∏ –∏–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤ DOCKER/docker-compose.yml, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –ª–∏ URL, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–≤–æ–¥–∏—Ç—Å—è –≤ –Ω–æ—É—Ç–±—É–∫–µ, —Ç–æ–º—É, —á—Ç–æ –æ–∂–∏–¥–∞–µ—Ç Spark (–æ–±—ã—á–Ω–æ —ç—Ç–æ local[*])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d407181-d301-4904-9b6c-d14165bb8fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL –º–∞—Å—Ç–µ—Ä–∞: local[*]\n",
      "–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: case4\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"case4\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "print(f\"URL –º–∞—Å—Ç–µ—Ä–∞: {spark.sparkContext.master}\")\n",
    "print(f\"–ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {spark.sparkContext.appName}\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c140570d-841b-4100-a116-f25581401d74",
   "metadata": {},
   "source": [
    "### –ö–µ–π—Å 1.5. (–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é):\n",
    "- –°–æ–∑–¥–∞–π—Ç–µ —Å–µ—Å—Å–∏—é, —è–≤–Ω–æ —É–∫–∞–∑–∞–≤ –≤ config (—á–µ—Ä–µ–∑ .config(\"spark.driver.memory\", \"512m\")) –º–µ–Ω—å—à–∏–π –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏ –¥–ª—è –¥—Ä–∞–π–≤–µ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 512 –ú–ë). –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, —á—Ç–æ —Å–µ—Å—Å–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–ª–∞—Å—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3931526-ce62-41d2-9a98-29ab89ec367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–°–µ—Å—Å–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞! –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è - case5\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"case5\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"512m\") \\\n",
    "        .getOrCreate()\n",
    "print(f\"–°–µ—Å—Å–∏—è —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞! –ò–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è - {spark.sparkContext.appName}\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c8b874-7b8e-449e-b42a-235ba367d907",
   "metadata": {},
   "source": [
    "### –ó–∞–¥–∞—á–∞ 1.6. (–ò–Ω—Å–ø–µ–∫—Ç–æ—Ä –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏):\n",
    "- –°–æ–∑–¥–∞–π—Ç–µ —Å–µ—Å—Å–∏—é. –ò—Å–ø–æ–ª—å–∑—É—è spark.sparkContext.getConf().getAll(), –ø–æ–ª—É—á–∏—Ç–µ –∏ —Ä–∞—Å–ø–µ—á–∞—Ç–∞–π—Ç–µ –≤—Å–µ –∞–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Spark (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –æ–±—ä–µ–º –ø–∞–º—è—Ç–∏). –≠—Ç–æ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –Ω–∞–≤—ã–∫ –æ–±—Ä–∞—â–µ–Ω–∏—è –∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f42471d-41a3-45e0-b2e2-068271efe7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:\n",
      "spark.executor.instances 3\n",
      "spark.app.id local-1764456646091\n",
      "spark.executor.memory 4g\n",
      "spark.executor.id driver\n",
      "spark.executor.cores 2\n",
      "spark.driver.memory 512m\n",
      "spark.driver.extraJavaOptions -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.driver.host d394ecff4ed5\n",
      "spark.app.submitTime 1764454422741\n",
      "spark.app.startTime 1764456646020\n",
      "spark.rdd.compress True\n",
      "spark.serializer.objectStreamReset 100\n",
      "spark.master local[*]\n",
      "spark.submit.pyFiles \n",
      "spark.submit.deployMode client\n",
      "spark.driver.port 46559\n",
      "spark.app.name Inspect_config\n",
      "spark.sql.shuffle.partitions 8\n",
      "spark.ui.showConsoleProgress true\n",
      "spark.executor.extraJavaOptions -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Inspect_config\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"512m\") \\\n",
    "        .getOrCreate()\n",
    "lst_configs = spark.sparkContext.getConf().getAll()\n",
    "print(f\"–¢–µ–∫—É—â–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è:\")\n",
    "for c, v in lst_configs:\n",
    "    print(c, v)\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe769e3-a001-4ee4-85c7-ea5147126732",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
