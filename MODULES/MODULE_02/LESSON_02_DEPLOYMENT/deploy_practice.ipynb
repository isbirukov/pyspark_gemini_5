{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d59ddbc-fd28-49b8-9387-a41d75252123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/03 15:10:55 INFO SparkContext: Running Spark version 3.5.0\n",
      "25/12/03 15:10:55 INFO SparkContext: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/12/03 15:10:55 INFO SparkContext: Java version 17.0.8.1\n",
      "25/12/03 15:10:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/03 15:10:55 INFO ResourceUtils: ==============================================================\n",
      "25/12/03 15:10:55 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/12/03 15:10:55 INFO ResourceUtils: ==============================================================\n",
      "25/12/03 15:10:55 INFO SparkContext: Submitted application: MyProdJob\n",
      "25/12/03 15:10:55 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/12/03 15:10:55 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/12/03 15:10:55 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/12/03 15:10:55 INFO SecurityManager: Changing view acls to: jovyan\n",
      "25/12/03 15:10:55 INFO SecurityManager: Changing modify acls to: jovyan\n",
      "25/12/03 15:10:55 INFO SecurityManager: Changing view acls groups to: \n",
      "25/12/03 15:10:55 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/12/03 15:10:55 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: jovyan; groups with view permissions: EMPTY; users with modify permissions: jovyan; groups with modify permissions: EMPTY\n",
      "25/12/03 15:10:55 INFO Utils: Successfully started service 'sparkDriver' on port 33613.\n",
      "25/12/03 15:10:55 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/12/03 15:10:55 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/12/03 15:10:55 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/12/03 15:10:55 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/12/03 15:10:55 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/12/03 15:10:55 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-65903b66-7b4a-4c9b-876b-8367b5b7ebb2\n",
      "25/12/03 15:10:55 INFO MemoryStore: MemoryStore started with capacity 2.2 GiB\n",
      "25/12/03 15:10:55 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/12/03 15:10:55 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "25/12/03 15:10:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/12/03 15:10:55 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "25/12/03 15:10:56 INFO Executor: Starting executor ID driver on host a03ea00e53ef\n",
      "25/12/03 15:10:56 INFO Executor: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/12/03 15:10:56 INFO Executor: Java version 17.0.8.1\n",
      "25/12/03 15:10:56 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/12/03 15:10:56 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@5280315d for default.\n",
      "25/12/03 15:10:56 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43653.\n",
      "25/12/03 15:10:56 INFO NettyBlockTransferService: Server created on a03ea00e53ef:43653\n",
      "25/12/03 15:10:56 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/12/03 15:10:56 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a03ea00e53ef, 43653, None)\n",
      "25/12/03 15:10:56 INFO BlockManagerMasterEndpoint: Registering block manager a03ea00e53ef:43653 with 2.2 GiB RAM, BlockManagerId(driver, a03ea00e53ef, 43653, None)\n",
      "25/12/03 15:10:56 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a03ea00e53ef, 43653, None)\n",
      "25/12/03 15:10:56 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a03ea00e53ef, 43653, None)\n",
      "üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: Production_App_Run1\n",
      "25/12/03 15:10:57 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/12/03 15:10:57 INFO SharedState: Warehouse path is 'file:/home/jovyan/workspace/MODULES/MODULE_02/LESSON_02_DEPLOYMENT/spark-warehouse'.\n",
      "25/12/03 15:10:58 INFO CodeGenerator: Code generated in 167.543486 ms\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 8 output partitions\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/12/03 15:10:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.9 KiB, free 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on a03ea00e53ef:43653 (size: 7.1 KiB, free: 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Submitting 8 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7))\n",
      "25/12/03 15:10:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 8 tasks resource profile 0\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (a03ea00e53ef, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (a03ea00e53ef, executor driver, partition 1, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (a03ea00e53ef, executor driver, partition 2, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (a03ea00e53ef, executor driver, partition 3, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (a03ea00e53ef, executor driver, partition 4, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (a03ea00e53ef, executor driver, partition 5, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (a03ea00e53ef, executor driver, partition 6, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (a03ea00e53ef, executor driver, partition 7, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:10:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)\n",
      "25/12/03 15:10:59 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)\n",
      "25/12/03 15:10:59 INFO CodeGenerator: Code generated in 14.791671 ms\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1984 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1984 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 2027 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 300 ms on a03ea00e53ef (executor driver) (1/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 300 ms on a03ea00e53ef (executor driver) (2/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 299 ms on a03ea00e53ef (executor driver) (3/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 303 ms on a03ea00e53ef (executor driver) (4/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 301 ms on a03ea00e53ef (executor driver) (5/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 306 ms on a03ea00e53ef (executor driver) (6/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 325 ms on a03ea00e53ef (executor driver) (7/8)\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 304 ms on a03ea00e53ef (executor driver) (8/8)\n",
      "25/12/03 15:10:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/12/03 15:10:59 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 0.460 s\n",
      "25/12/03 15:10:59 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/12/03 15:10:59 INFO DAGScheduler: running: Set()\n",
      "25/12/03 15:10:59 INFO DAGScheduler: waiting: Set()\n",
      "25/12/03 15:10:59 INFO DAGScheduler: failed: Set()\n",
      "25/12/03 15:10:59 INFO CodeGenerator: Code generated in 9.444879 ms\n",
      "25/12/03 15:10:59 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Missing parents: List()\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/12/03 15:10:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on a03ea00e53ef:43653 (size: 5.9 KiB, free: 2.2 GiB)\n",
      "25/12/03 15:10:59 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/12/03 15:10:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8) (a03ea00e53ef, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "25/12/03 15:10:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 8)\n",
      "25/12/03 15:10:59 INFO ShuffleBlockFetcherIterator: Getting 8 (480.0 B) non-empty blocks including 8 (480.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/12/03 15:10:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "25/12/03 15:10:59 INFO CodeGenerator: Code generated in 8.397639 ms\n",
      "25/12/03 15:10:59 INFO Executor: Finished task 0.0 in stage 2.0 (TID 8). 4038 bytes result sent to driver\n",
      "25/12/03 15:10:59 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 59 ms on a03ea00e53ef (executor driver) (1/1)\n",
      "25/12/03 15:10:59 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/12/03 15:10:59 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.068 s\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/12/03 15:10:59 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/12/03 15:10:59 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.080613 s\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–¥—Å—á–µ—Ç–∞: 999979\n",
      "‚è≥ –°–ø–∏–º 30 —Å–µ–∫—É–Ω–¥ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ Spark UI)...\n",
      "25/12/03 15:11:29 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "25/12/03 15:11:29 INFO SparkUI: Stopped Spark web UI at http://a03ea00e53ef:4041\n",
      "25/12/03 15:11:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "25/12/03 15:11:29 INFO MemoryStore: MemoryStore cleared\n",
      "25/12/03 15:11:29 INFO BlockManager: BlockManager stopped\n",
      "25/12/03 15:11:29 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "25/12/03 15:11:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "25/12/03 15:11:29 INFO SparkContext: Successfully stopped SparkContext\n",
      "‚úÖ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n",
      "25/12/03 15:11:30 INFO ShutdownHookManager: Shutdown hook called\n",
      "25/12/03 15:11:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-252aa048-d424-41b6-bcb9-44002c4cf545/pyspark-988f6bb0-5801-4ba5-a523-fc6e01dde863\n",
      "25/12/03 15:11:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-252aa048-d424-41b6-bcb9-44002c4cf545\n",
      "25/12/03 15:11:30 INFO ShutdownHookManager: Deleting directory /tmp/spark-4a1bfc82-7745-4dff-9044-132731e2f560\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Å–∫—Ä–∏–ø—Ç, –ø–µ—Ä–µ–¥–∞–≤–∞—è –∞—Ä–≥—É–º–µ–Ω—Ç \"Run1\"\n",
    "# --master local[*] : –∏—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π —Ä–µ–∂–∏–º (–∫–∞–∫ –≤ –Ω–æ—É—Ç–±—É–∫–µ)\n",
    "# --name \"MyProdJob\" : –∏–º—è –≤ UI\n",
    "!/usr/local/spark/bin/spark-submit \\\n",
    "  --master local[*] \\\n",
    "  --name \"MyProdJob\" \\\n",
    "  /home/jovyan/workspace/MODULES/MODULE_02/LESSON_02_DEPLOYMENT/production_app.py \"Run1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0fe67a-79f1-4479-a74d-b990261da933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/12/03 15:15:15 INFO SparkContext: Running Spark version 3.5.0\n",
      "25/12/03 15:15:15 INFO SparkContext: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/12/03 15:15:15 INFO SparkContext: Java version 17.0.8.1\n",
      "25/12/03 15:15:15 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/12/03 15:15:15 INFO ResourceUtils: ==============================================================\n",
      "25/12/03 15:15:15 INFO ResourceUtils: No custom resources configured for spark.driver.\n",
      "25/12/03 15:15:15 INFO ResourceUtils: ==============================================================\n",
      "25/12/03 15:15:15 INFO SparkContext: Submitted application: production_app.py\n",
      "25/12/03 15:15:15 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 512, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)\n",
      "25/12/03 15:15:15 INFO ResourceProfile: Limiting resource is cpu\n",
      "25/12/03 15:15:15 INFO ResourceProfileManager: Added ResourceProfile id: 0\n",
      "25/12/03 15:15:15 INFO SecurityManager: Changing view acls to: jovyan\n",
      "25/12/03 15:15:15 INFO SecurityManager: Changing modify acls to: jovyan\n",
      "25/12/03 15:15:15 INFO SecurityManager: Changing view acls groups to: \n",
      "25/12/03 15:15:15 INFO SecurityManager: Changing modify acls groups to: \n",
      "25/12/03 15:15:15 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: jovyan; groups with view permissions: EMPTY; users with modify permissions: jovyan; groups with modify permissions: EMPTY\n",
      "25/12/03 15:15:15 INFO Utils: Successfully started service 'sparkDriver' on port 41135.\n",
      "25/12/03 15:15:15 INFO SparkEnv: Registering MapOutputTracker\n",
      "25/12/03 15:15:15 INFO SparkEnv: Registering BlockManagerMaster\n",
      "25/12/03 15:15:15 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "25/12/03 15:15:15 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "25/12/03 15:15:15 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "25/12/03 15:15:15 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-17d9ea66-982f-4eac-ba5d-7aff1c87191e\n",
      "25/12/03 15:15:15 INFO MemoryStore: MemoryStore started with capacity 127.2 MiB\n",
      "25/12/03 15:15:15 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "25/12/03 15:15:15 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI\n",
      "25/12/03 15:15:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/12/03 15:15:15 INFO Utils: Successfully started service 'SparkUI' on port 4041.\n",
      "25/12/03 15:15:15 INFO Executor: Starting executor ID driver on host a03ea00e53ef\n",
      "25/12/03 15:15:15 INFO Executor: OS info Linux, 6.8.0-87-generic, amd64\n",
      "25/12/03 15:15:15 INFO Executor: Java version 17.0.8.1\n",
      "25/12/03 15:15:15 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''\n",
      "25/12/03 15:15:15 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@14812426 for default.\n",
      "25/12/03 15:15:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41185.\n",
      "25/12/03 15:15:15 INFO NettyBlockTransferService: Server created on a03ea00e53ef:41185\n",
      "25/12/03 15:15:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "25/12/03 15:15:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, a03ea00e53ef, 41185, None)\n",
      "25/12/03 15:15:15 INFO BlockManagerMasterEndpoint: Registering block manager a03ea00e53ef:41185 with 127.2 MiB RAM, BlockManagerId(driver, a03ea00e53ef, 41185, None)\n",
      "25/12/03 15:15:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, a03ea00e53ef, 41185, None)\n",
      "25/12/03 15:15:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, a03ea00e53ef, 41185, None)\n",
      "üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: Production_App_LowResRun\n",
      "25/12/03 15:15:17 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.\n",
      "25/12/03 15:15:17 INFO SharedState: Warehouse path is 'file:/home/jovyan/workspace/MODULES/MODULE_02/LESSON_02_DEPLOYMENT/spark-warehouse'.\n",
      "25/12/03 15:15:18 INFO CodeGenerator: Code generated in 168.667683 ms\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Registering RDD 3 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Got map stage job 0 (count at NativeMethodAccessorImpl.java:0) with 2 output partitions\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Final stage: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Parents of final stage: List()\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Missing parents: List()\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/12/03 15:15:18 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 14.9 KiB, free 127.2 MiB)\n",
      "25/12/03 15:15:18 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 7.1 KiB, free 127.2 MiB)\n",
      "25/12/03 15:15:18 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on a03ea00e53ef:41185 (size: 7.1 KiB, free: 127.2 MiB)\n",
      "25/12/03 15:15:18 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580\n",
      "25/12/03 15:15:18 INFO DAGScheduler: Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\n",
      "25/12/03 15:15:18 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0\n",
      "25/12/03 15:15:18 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (a03ea00e53ef, executor driver, partition 0, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:15:18 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (a03ea00e53ef, executor driver, partition 1, PROCESS_LOCAL, 7729 bytes) \n",
      "25/12/03 15:15:18 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)\n",
      "25/12/03 15:15:18 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)\n",
      "25/12/03 15:15:19 INFO CodeGenerator: Code generated in 15.512353 ms\n",
      "25/12/03 15:15:19 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1984 bytes result sent to driver\n",
      "25/12/03 15:15:19 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1984 bytes result sent to driver\n",
      "25/12/03 15:15:19 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 216 ms on a03ea00e53ef (executor driver) (1/2)\n",
      "25/12/03 15:15:19 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 197 ms on a03ea00e53ef (executor driver) (2/2)\n",
      "25/12/03 15:15:19 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "25/12/03 15:15:19 INFO DAGScheduler: ShuffleMapStage 0 (count at NativeMethodAccessorImpl.java:0) finished in 0.343 s\n",
      "25/12/03 15:15:19 INFO DAGScheduler: looking for newly runnable stages\n",
      "25/12/03 15:15:19 INFO DAGScheduler: running: Set()\n",
      "25/12/03 15:15:19 INFO DAGScheduler: waiting: Set()\n",
      "25/12/03 15:15:19 INFO DAGScheduler: failed: Set()\n",
      "25/12/03 15:15:19 INFO CodeGenerator: Code generated in 10.95733 ms\n",
      "25/12/03 15:15:19 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Got job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Final stage: ResultStage 2 (count at NativeMethodAccessorImpl.java:0)\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Missing parents: List()\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0), which has no missing parents\n",
      "25/12/03 15:15:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 12.5 KiB, free 127.2 MiB)\n",
      "25/12/03 15:15:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 127.2 MiB)\n",
      "25/12/03 15:15:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on a03ea00e53ef:41185 (size: 5.9 KiB, free: 127.2 MiB)\n",
      "25/12/03 15:15:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[6] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\n",
      "25/12/03 15:15:19 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0\n",
      "25/12/03 15:15:19 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (a03ea00e53ef, executor driver, partition 0, NODE_LOCAL, 7615 bytes) \n",
      "25/12/03 15:15:19 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)\n",
      "25/12/03 15:15:19 INFO ShuffleBlockFetcherIterator: Getting 2 (120.0 B) non-empty blocks including 2 (120.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks\n",
      "25/12/03 15:15:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms\n",
      "25/12/03 15:15:19 INFO CodeGenerator: Code generated in 6.867088 ms\n",
      "25/12/03 15:15:19 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4038 bytes result sent to driver\n",
      "25/12/03 15:15:19 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 60 ms on a03ea00e53ef (executor driver) (1/1)\n",
      "25/12/03 15:15:19 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool \n",
      "25/12/03 15:15:19 INFO DAGScheduler: ResultStage 2 (count at NativeMethodAccessorImpl.java:0) finished in 0.072 s\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job\n",
      "25/12/03 15:15:19 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished\n",
      "25/12/03 15:15:19 INFO DAGScheduler: Job 1 finished: count at NativeMethodAccessorImpl.java:0, took 0.095919 s\n",
      "üìä –†–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–¥—Å—á–µ—Ç–∞: 999979\n",
      "‚è≥ –°–ø–∏–º 30 —Å–µ–∫—É–Ω–¥ (–ø—Ä–æ–≤–µ—Ä—å—Ç–µ Spark UI)...\n",
      "25/12/03 15:15:49 INFO SparkContext: SparkContext is stopping with exitCode 0.\n",
      "25/12/03 15:15:49 INFO SparkUI: Stopped Spark web UI at http://a03ea00e53ef:4041\n",
      "25/12/03 15:15:49 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\n",
      "25/12/03 15:15:49 INFO MemoryStore: MemoryStore cleared\n",
      "25/12/03 15:15:49 INFO BlockManager: BlockManager stopped\n",
      "25/12/03 15:15:49 INFO BlockManagerMaster: BlockManagerMaster stopped\n",
      "25/12/03 15:15:49 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\n",
      "25/12/03 15:15:49 INFO SparkContext: Successfully stopped SparkContext\n",
      "‚úÖ –†–∞–±–æ—Ç–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.\n",
      "25/12/03 15:15:49 INFO ShutdownHookManager: Shutdown hook called\n",
      "25/12/03 15:15:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-b7393da2-7df5-4d69-8524-4dbc9a307bf3\n",
      "25/12/03 15:15:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-c13b1aea-9bc8-4520-8c32-2f06d5e3ce6e/pyspark-38199e6c-e7d5-4de6-a6b4-60266af08e94\n",
      "25/12/03 15:15:49 INFO ShutdownHookManager: Deleting directory /tmp/spark-c13b1aea-9bc8-4520-8c32-2f06d5e3ce6e\n"
     ]
    }
   ],
   "source": [
    "# –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–∞–º—è—Ç—å –¥—Ä–∞–π–≤–µ—Ä–∞ –∏ —ç–∫–∑–µ–∫—å—é—Ç–æ—Ä–∞\n",
    "!/usr/local/spark/bin/spark-submit \\\n",
    "  --master local[2] \\\n",
    "  --conf \"spark.driver.memory=512m\" \\\n",
    "  --conf \"spark.executor.memory=512m\" \\\n",
    "  /home/jovyan/workspace/MODULES/MODULE_02/LESSON_02_DEPLOYMENT/production_app.py \"LowResRun\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70aa62-4d29-4089-b60d-c0087299dd41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
