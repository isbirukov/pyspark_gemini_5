# Конспект: Чтение и Запись (I/O)

## 1. Основные форматы
| Формат | Тип | Плюсы | Минусы | Применение |
| :--- | :--- | :--- | :--- | :--- |
| **CSV** | Текст, Строковый | Читаем глазами, совместим везде | Нет схемы, тяжелый, медленный | Обмен данными с Excel/Legacy |
| **JSON** | Текст, Строковый | Иерархия, веб-стандарт | Очень тяжелый, медленный парсинг | Логи, API ответы |
| **Parquet** | Бинарный, Колоночный | Сжатие, Схема, **Column Pruning** | Нельзя прочесть глазами | Хранилища данных (DWH) |

## 2. API
* **Чтение:** `spark.read.format("...").options(...).schema(...).load("path")`
* **Запись:** `df.write.format("...").mode("...").save("path")`

## 3. Режимы записи (Mode)
* `overwrite`: Удалить и перезаписать.
* `append`: Дописать вниз.

## 4. Партиционирование
Физическое разделение данных по папкам.
`df.write.partitionBy("year", "month")`
Создает структуру: `/year=2023/month=01/data.parquet`.
**Польза:** Spark читает только нужные папки при фильтрации (Partition Pruning).
